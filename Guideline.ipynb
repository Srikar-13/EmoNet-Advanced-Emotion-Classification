{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "754089db",
   "metadata": {},
   "source": [
    "# EmoNet: Advanced Emotion Classification Using NLP Techniques\n",
    "## Problem Statement:\n",
    "\n",
    "Create an advanced emotion classification model leveraging state-of-the-art Natural Language Processing (NLP) techniques to accurately identify and categorize emotions expressed in textual data. The objective is to develop a model capable of effectively predicting the emotional sentiment associated with each document in a given dataset. This entails training the model on a diverse corpus of documents annotated with corresponding emotion labels and optimizing its performance to achieve high accuracy and robustness in classifying emotions across various contexts. The resulting model should exhibit superior capabilities in understanding and interpreting nuanced emotional nuances, enabling its application in a wide range of real-world scenarios such as sentiment analysis, customer feedback analysis, and mood detection in conversational interfaces.\n",
    "\n",
    "## Aim:\n",
    "\n",
    "- Develop a high-performing emotion classification model using NLP techniques to accurately categorize emotions expressed in textual data.\n",
    "\n",
    "## Dataset Attributes\n",
    "\n",
    "- Text Data: Each entry contains a piece of text representing a statement or expression of emotion. These textual documents vary in length and content, reflecting the diverse range of emotional experiences.\n",
    "\n",
    "- Emotion Label: The emotion label indicates the predominant emotion conveyed in the corresponding text data. Emotions such as sorrow, rage, happiness, amaze, care, and scare are represented in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efda021e",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23587651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14fc0d7f",
   "metadata": {},
   "source": [
    "# Questions\n",
    "**Instructions:**\n",
    "1.  Answer all questions.\n",
    "2.  Justify your answers with appropriate reasoning, code, or calculations.\n",
    "3.  Ensure your code is well-commented to explain your logic.\n",
    "4.  Total Marks: 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb83477",
   "metadata": {},
   "source": [
    "# Question 1 : Data Analysis (10 pt)\n",
    "\n",
    "- Describe the dataset, including the number of entries (documents) present.\n",
    "- Determine the frequency of each emotion category in the dataset.\n",
    "- Utilize visualizations such as bar charts or pie charts to display the distribution of emotions in the dataset.\n",
    "- Interpret the statistical plots to extract meaningful insights that can inform the development of the EmoNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae6faba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56a487af",
   "metadata": {},
   "source": [
    "# Question 2: Data pre-processing & Feature Engineering (10 points)\n",
    "\n",
    "- Preprocess the text data to remove noise and irrelevant information, such as punctuation, special characters, and stop words.\n",
    "- Perform tokenization to break down the text data into individual words or tokens.\n",
    "- Using the provided dataset, create a word cloud to visualize the frequency of words in the text. Describe the process you followed to create the word cloud.\n",
    "- Experiment with different text representation techniques, such as frequency vector, TF-IDF (Term Frequency-Inverse Document Frequency)to transform the text data into numerical features that can be used by machine learning models.\n",
    "### Extra credit if you perform word embeddings (e.g., Word2Vec, GloVe) to transform the text data into numerical features that can be used by machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085abf67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86bacf86",
   "metadata": {},
   "source": [
    "# Question 3 - LDA(10 points)\n",
    "\n",
    "- Apply Latent Dirichlet Allocation (LDA) to uncover themes in the text data. Set the number of topics to 8 and extract 10 keywords per topic. \n",
    "- Describe your approach, including any preprocessing steps. Present the identified topics with their keywords. \n",
    "- Discuss the importance of topic modeling in revealing hidden themes and extracting insights from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc0019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e79f2a5b",
   "metadata": {},
   "source": [
    "# Question 4 - Modeling (20 points)\n",
    "\n",
    "- Train at least three different  models.\n",
    "- Choose the best feature engineering method and perform grid search & cross-validation to tune hyperparameters for three different models, optimizing their performance for emotion classification and Also, for each model, plot the ROC-AUC curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a5eb78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2221e3f6",
   "metadata": {},
   "source": [
    "# Question 5 - Evaluation and Reporting (20 points)\n",
    "\n",
    "- Select a model that is expected to perform optimally on the unseen data and provide the predictions accordingly. Give clear conclusions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d7948c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "828f19f7",
   "metadata": {},
   "source": [
    "# Question 6 : External validation (30 pt)\n",
    "\n",
    "- A dataset named ‘test.csv’ is provided to you in which the label is hidden. You have to choose the best model(the model which has the highest score) and then use that model to predict the label on the ‘test.csv’.\n",
    "- You need to generate a csv file, named as \"submission.csv\". This is the inference values from your selected best model on \"test.csv\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b486ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is psudo-code. Each student have to use their actual code for this.\n",
    "\n",
    "# step 1. Load the  data\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "# perform preprocessing\n",
    "\n",
    "# step 4. Make predictions\n",
    "pred = .....(test)\n",
    "\n",
    "# step 5. Save output as csv file\n",
    "pred = pd.DataFrame(pred)\n",
    "pred.to_csv('./submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e50c473",
   "metadata": {},
   "source": [
    "# Hint - Final evaluation metrics\n",
    "Please use the below function named 'model_evaluation' in order to calculate the evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b70ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def evaluation_metrics(y_test, y_pred):\n",
    "    # Calculate the balanced accuracy score\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Return the balanced accuracy as a single digit number\n",
    "    print('The Balanced accuracy is : ', balanced_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
